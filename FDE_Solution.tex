\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf}
\usepackage[a4paper]{geometry}
\usepackage{fancyhdr}
\usepackage{mathtools}
\pagestyle{fancy}
\begin{document}

\setlength\parindent{0pt}
\setlength{\parskip}{5mm plus4mm minus3mm}
\fancyfoot[l]{Adam J. Gray}
\fancyfoot[r]{\today}
\fancyhead[l]{BlackHat Maths}
\fancyhead[r]{Solution to a Simple FDE}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newcommand{\laplace}[1]{ \mathcal{L} \left\{ #1 \right\} }
\newcommand{\rld}[3]{ \left( \mathcal{D}_{#1}^{#2} #3 \right) }
\newcommand{\rli}[3]{ \left( I_{#1}^{#2} #3 \right) }
\newcommand{\der}[3]{ \frac{d^{#3}#1}{d#2^{#3}} }
\newcommand{\capder}[3]{ \left( \prescript{C}{}{\mathcal{D}_{#1}^{#2}} #3 \right) }
\section*{Solution to a Simple FDE}

We aim to get a solution to the following fractional differential equation (in terms of Caputo derivatives)


\begin{align}
	\label{eq:fde-1}
	\left( \prescript{C}{}{\mathcal{D}_0^\alpha}y \right)(t) = \beta y(t) 
\end{align}

along with the initial conditions 
\begin{align}
	\label{eq:fde-1-ic}
	y^{(k)}(0) = 
	\begin{cases}
		1 & k = 0 \\
		0 & 1 \leq k \leq \lfloor \alpha \rfloor - 1  
	\end{cases}
\end{align}

has the solution $ y(t) = E_\alpha \left( \beta t^\alpha \right) $. Where $ E_\alpha $ is the one parameter Mittag-Lefler function.

This solution is arrived at by a Laplace transform method. We will then go on to show that this solution is unique. The proof of that fact, will be 
presented via the proof of a more general theorem, which broadly follows a Banach fixed point method. 

\begin{definition}[Fractional Derivatives and Integrals]
	For $ \alpha > 0 $ we define
	\begin{align*}
		(I_{a+}^{\alpha}f)(x) := \frac{1}{\Gamma(\alpha)}\int_a^x \frac{f(t)}{(x-t)^{1 - \alpha}} dt \\
		(\mathcal{D}_{a+}^{\alpha}f)(x) := \frac{1}{\Gamma(n-\alpha)} \frac{d^n}{dx^n}\int_a^x \frac{f(t)}{(x-t)^{\alpha - n + 1}} dt \\
		(\prescript{C}{}{\mathcal{D}}_{a+}^\alpha f)(x) := I_{0}^{n-\alpha} \frac{d^n}{dx^n}f(x) 
	\end{align*}
	where $ n  = \lceil \alpha \rceil - 1$.
	We will refer to $ I_{a+}^\alpha f$ as the (Riemann Louiville) integral $ f $ of over $ \alpha $ (based at $ a $).
	Likewise we refer to $ \mathcal{D}_{a+}^\alpha f $ as the (Riemann Louiville) derivative of order $ \alpha $ (based at $ a $).
	We also refer to $ \prescript{C}{}{\mathcal{D}}_{a+}^\alpha f $ as the Caputo derivative of order $ \alpha $ (based at $ a $).
	
\end{definition}

The motivation for these definitions are based of the Cauchy formula for repeated integration, and in the case
of the Caputo derivative, practical considerations. \cite{Samko1993, Podlubny1999} 

For the rest of our considerations we will take $ a = 1 $ (based at 0). 

We now consider the Laplace transform of the fractional integration and differentiation operators.

\begin{lemma}
	$$
		\mathcal{L} \left\{ I_0^\alpha f \right\}  = s^{-\alpha} \mathcal{L} \left\{ f \right\}
	$$
\end{lemma}
\begin{proof}
	Since 
	$$
		 (I_0^\alpha f)(t) = \frac{1}{\Gamma(\alpha)} \int_0^x f(u) (t-u)^{\alpha - 1} du
	$$
	is just $ \frac{1}{\Gamma(\alpha)} $ times the convolution of $ f $ with $ t^{\alpha - 1} $ then by the convolution theorem
	for Laplace transforms we have that 
	\begin{align*}
		\mathcal{L} \left\{ I_0^\alpha f \right\} &= \frac{1}{\Gamma(\alpha)} \mathcal{L} \left\{ \int_{0}^{t} f(u) (t-u)^{\alpha - 1} du \right\} \\
			&= \frac{1}{\Gamma(\alpha)} \mathcal{L} \left\{ f(t) \right\} \underbrace{\mathcal{L} \left\{ t^{\alpha - 1} \right\}}_{=s^{-\alpha} \Gamma(\alpha)} \\
			&= s^{-\alpha} \mathcal{L} \left\{ f \right\}.
	\end{align*}
\end{proof}

\begin{lemma}
	\begin{align*}
		\mathcal{L} \left\{\mathcal{D}_0^\alpha f\right\} = s^\alpha \mathcal{L} \left\{ f \right\} - \sum_{k=0}^{n-1} s^{k-1} \left( \mathcal{D}_0^{\alpha-k} f\right)(0)
	\end{align*}
\end{lemma}
\begin{proof}
	See that
	\begin{align*}
		\laplace{ \rld{0}{\alpha}{f} } &= \laplace{ \der{}{t}{n} \rli{0}{n-\alpha}{f} } \\
			&= s\laplace{\rli{0}{n-\alpha}{f}} - \sum_{k=0}^{n-1} s^k \der{}{t}{n-k-1} \rli{0}{n-\alpha}{f}(0) \\
			&= s\laplace{\rli{0}{n-\alpha}{f}} - \sum_{k=0}^{n-1} s^{k-1} \rld{0}{\alpha - k}{f}(0). 
	\end{align*}
\end{proof}

\begin{lemma}
\label{lem:lap_cap}

	\begin{align*}
		\laplace{\capder{0}{\alpha}{f}} = s^{\alpha - n} \left[ s^n \laplace{f} - \sum_{k=0}^{n-1} s^{n-k-1} \left( \der{f}{t}{k} \right)(0) \right]
	\end{align*}
\end{lemma}
\begin{proof}
	See that
	\begin{align*}
		\laplace{\capder{0}{\alpha}{f}} &= \laplace{ \frac{1}{\Gamma(n-\alpha)} \rli{0}{n-\alpha}{\der{f}{t}{n}}} \\
			&= \frac{1}{\Gamma(n-\alpha)}\laplace{ \int_0^t (t-u)^{n-\alpha-1} \der{f}{t}{n} du} \\ 
	\end{align*}
	which is the Laplace transform of a convolution so
	\begin{align*}
		\Gamma(n-\alpha)\laplace{ \int_0^t (t-u)^{n-\alpha-1} \der{f}{t}{n} du} &= \laplace{t^{n-\alpha-1}} \laplace{\der{f}{t}{n}} \\
		&= \frac{1}{n-\alpha} \left( s^{-(n-\alpha)} \Gamma(n-\alpha) \right) \left( s^n \laplace{f} - \sum_{k=0}^{n-1} s^{n-k-1} \left( \der{f}{t}{k} \right)(0) \right) \\
		&= s^{\alpha - n} \left[ s^n \laplace{f} - \sum_{k=0}^{n-1} s^{n-k-1} \left( \der{f}{t}{k} \right)(0) \right].
	\end{align*}	
\end{proof}

We now define the Mittag-Lefler function and calculate its Laplace transform.

\begin{definition}
	The one parameter Mittag-Lefler $ E_\alpha $ function is defined by its power series.
	$$
		E_\alpha(t) = \sum_{k=0}^{\infty} \frac{t^k}{\Gamma(\alpha k + 1)}
	$$
\end{definition}
It is clear to see the definition of this function is inspired by the exponential function. Before we can calculate the 
Laplace transform of the Mittag-Lefler function we have to prove a simple lemma about the convergence of the 
series which is used in its definition.

\begin{lemma}
\label{lem:mit_conv}

	The series
	$$
		\sum_{k=0}^{\infty} \frac{t^k}{\Gamma(\alpha k + 1)} 
	$$
  	converges absolutely for all $ t \in \mathbb{R} $.
\end{lemma}
\begin{proof}
	Let $ a_k = \frac{t^k}{\Gamma(\alpha k + 1) }$ and see that
	$$ \lvert \frac{a_{k+1}}{a_k} \rvert = |t| \frac{\Gamma(\alpha k + 1) }{\Gamma(\alpha(k+1) + 1)} $$
	and that hence 
	$$
		\lim_{k \longrightarrow \infty} \lvert \frac{a_{k+1}}{a_k} \rvert = 0
	$$
	for all $ t \in \mathbb{R} $ so by the ratio test, the series $ \sum_{k=0}^{\infty} \frac{t^k}{\Gamma(\alpha k + 1)}  $
	converges for all $ t \in \mathbb{R} $.
\end{proof}
\begin{lemma}
\label{lem:lap_mit}

	\begin{align*}	
		\laplace{ E_\alpha (\beta t^\alpha)} = \frac{s^{\alpha - 1}}{s^\alpha - \beta}
	\end{align*}
\end{lemma}
\begin{proof}
	See that
	\begin{align*}
		\laplace{ E_\alpha (\beta t^\alpha)} = \int_0^\infty e^{-st} \sum_{k=0}^\infty \frac{(\beta t^\alpha)^k}{\Gamma(\alpha k+1)} dt
	\end{align*}
	and because the series converges absolutely for all $ t \in \mathbb{R} $ (lemma \ref{lem:mit_conv}) we may interchange the integral
	and the sum to get
	\begin{align*}
		\int_0^\infty e^{-st} \sum_{k=0}^\infty \frac{(\beta t^\alpha)^k}{\Gamma(\alpha k+1)} dt &= \sum_{k=0}^\infty \int_0^\infty e^{-st} \frac{(\beta t^\alpha)^k}{\Gamma(\alpha k + 1)} dt \\
			&= \sum_0^\infty \frac{\beta^k}{\Gamma(\alpha k + 1)} \int_0^\infty e^{-st} t^{\alpha k} dt. \\
	\end{align*}
	By performing the change of variables $ x =st $ we get that 
	\begin{align*}
		\sum_0^\infty \frac{\beta^k}{\Gamma(\alpha k + 1)} \int_0^\infty e^{-st} t^{\alpha k} dt 
			&= \sum_0^\infty \frac{\beta^k s^{-(k+1)}}{\Gamma(\alpha k + 1)} \underbrace{\int_0^\infty e^{-x} x^{\alpha k} dx}_{\Gamma(\alpha k + 1)} \\
			&= \sum_{k=0}^\infty \beta^{k} s^{-(\alpha k + 1)} \\
			&= \frac{s^{\alpha-1}}{s^\alpha - \beta}.		
	\end{align*}
	So we have that 
	\begin{align*}	
		\laplace{ E_\alpha (\beta t^\alpha)} = \frac{s^{\alpha - 1}}{s^\alpha - \beta}
	\end{align*}	
	as required.
\end{proof}

We now have sufficient tools to attack the original problem, that is finding a solution to \eqref{eq:fde-1}, \eqref{eq:fde-1-ic}.

\begin{lemma}
	The FDE defined in \eqref{eq:fde-1} and \eqref{eq:fde-1-ic}, restated here for completeness 
	\begin{align*}
		\left( \prescript{C}{}{\mathcal{D}_0^\alpha}y \right)(t) = \beta y(t) 
	\end{align*}

	along with the initial conditions 
	\begin{align*}
		y^{(k)}(0) = 
		\begin{cases}
			1 & k = 0 \\
			0 & 1 \leq k \leq \lfloor \alpha \rfloor - 1  
		\end{cases}
	\end{align*}
	has solution $ y(t) = E_\alpha \left( \beta t^\alpha \right) $.
\end{lemma}
\begin{proof}
	Taking the Laplace transform of both sides of \eqref{eq:fde-1} yields
	\begin{align*}
		\laplace{\capder{0}{\alpha}{y}} &= \beta \laplace{y} \\
		s^{-(n+\alpha)} \left[s^n \laplace{y} - \sum_{k=0}^{n-1} s^{n-k-1} y^{(k)}(0) \right] &= \beta \laplace{y}
	\end{align*}
	by the result of lemma \ref{lem:lap_cap}. 
	Then taking into account \eqref{eq:fde-1-ic} we get
	\begin{align*}
		s^{-(n+\alpha)} \left[s^n \laplace{y} - s^{n-1}\right] &= \beta \laplace{y}
	\end{align*}
	and so 
	\begin{align*}
		\laplace{y} = \frac{s^{\alpha-1}}{s^\alpha - \beta}.
	\end{align*}
	By using the result of lemma \ref{lem:lap_mit} we have that 
	\begin{align*}
		y(t) = E_\alpha(\beta t^\alpha)
	\end{align*}
\end{proof}

An obvious question to ask now, is whether the solution to \eqref{eq:fde-1}, \eqref{eq:fde-1-ic} is unique. To answer this in 
affirmative we will prove a result about the existence and uniqueness of solutions to non-linear Volterra integral equations of the second kind
then show that a more general FDE is equivalent to such a Volterra integral equation and hence arrive at the desired result. 
This technique follows that in \cite{Diethelm2002}. This 
is more general than what is required here, but it lays the groundwork for future results.

In order to use the Banach fixed point method we will need to preliminary definitions and theorems. 

\begin{definition}[Contraction Mapping]
Let $ (X,d) $ be a metric space then $ A : X \longrightarrow X $ is a contraction mapping if there exists
an $ 0 < \alpha < 1 $ such that
$$
	d(Ax,Ay) \leq d(x,y) 
$$
for all $ x, y \in X $. Call this $ \alpha $ the coefficient of contraction. 
\end{definition}

Note that it is immediately clear that a contraction mapping must be continuous.

\begin{theorem}[Banach Fixed Point Theorem]
	Let $ (X,d) $ be a complete metric space and let $ A $ be a contraction mapping on $ (X, d) $ with 
	coefficient of contraction $ \alpha $ then 
	there exists a unique $ x $ such that $ Ax = x $. We call this $ x $ the fixed point of $ A $. 
\end{theorem}
This proof follows that in \cite{Kolmogorov1975}, but the general method is essentially the same as Banach's
original proof of this theorem.
\begin{proof}
	Given an $ x_0 \in X $ let
	\begin{align*}
		x_1 = Ax_0 & x_2 = Ax_1 = A^2x_0 & \cdots & x_n = A^n x_0.
	\end{align*}
	We now show that this $ \left\{ x_n \right\}_n=0^\infty $ is a Cauchy sequence.
	Without loss of generality  let $m > n $ and note that
	\begin{align*}
		d(x_n, x_m) &= d(A^nx_0, A^mx_0) \\
			&\leq \alpha^n d(x_0, x_{m-n}) \\
			&\leq \alpha^n \left[ d(x_0, x_1) + d(x_1, x_2) + \ldots + d(x_{m-n-1}, x_{m-n}) \right] \\
			&\leq \alpha^n d(x_0, x_1) \left[ 1 + \alpha + \alpha^2 + \ldots + \alpha^{m-n-1} \right] \\
			&\leq \underbrace{d(x_0, x_1) \alpha^n \left( \frac{1}{1-\alpha} \right)}_{\circledast}.
	\end{align*}
	See that $ \circledast $ can be made arbitrarily small by making $ n $ large enough. So $ \left\{ x_n \right\}_{n=0}^\infty $
	is a Cauchy sequence and because $ (X, d) $ is complete $ \left\{ x_n \right\}_{n=0}^\infty  $ has a limit $ x \in X $.
	Now by the continuity of $ A $ we have that 
	\begin{align*}
		Ax &= A \lim_{n\longrightarrow \infty} x_n \\
			&= \lim_{n \longrightarrow \infty} Ax_n \\
			&= \lim_{n \longrightarrow \infty} x_{n+1} \\
			&= x
	\end{align*}
	So $ Ax = x $ which shows the existence of a fixed point. To see that $ x $ is unique assume that there
	are two fixed points $ x $ and $ y $. Then $ Ax = x $ and $ Ay = y $
	and $ d(x,y) \leq \alpha d(x,y) $, but since $ 0 < \alpha < 1 $ we have that $ d(x,y) = 0 $ which implies
	$ x = y $ and hence the fixed point $ x $ is unique.
\end{proof}

\begin{corollary}
	\label{cor:banach-fixed-point}
	Let $ (X, d) $ be a complete metric space and let $ A:X \longrightarrow X $ be a continuous mapping. Suppose 
	that for some $ n $, $ A^n $ is a contraction mapping, then $ A $ has a unique fixed point, $ x $.
\end{corollary}
\begin{proof}
	For an arbitrary $ x \in X $ let
	\begin{align*}
		x = \lim_{k \longrightarrow \infty} A^{kn} x_0
	\end{align*}
	and then by the continuity of $ A $
	\begin{align*}
		Ax = \lim_{k \longrightarrow \infty} AA^{kn} x_0
	\end{align*}
	and since $ A^n $ is a contraction then 
	\begin{align*}
		d(A^{kn}Ax_0, A^{kn}x_0) &\leq \alpha d(A^{(k-1)n}Ax_0, A^{(k-1)n}x_0 ) \\
			&\leq \alpha^k d(Ax_0, x_0).
	\end{align*}
	It follows that 
	\begin{align*}
		d(Ax, x) &= \lim_{k \longrightarrow \infty} d(AA^{kn}x_0,A^{kn}x_0) \\
			&= 0
	\end{align*}
	and so $ Ax = x $ which means $ x $ is a fixed point of $ A $.
	It is clear to see that $ x $ must be unique beucase if $ y $ is another fixed point of $ A $
	then $ y $ must be a fixed point of $ A^n $, but $ A^n $ is a contraction mapping so this would
	be a contradiction.
\end{proof}

\begin{lemma}
	Let $ K : [a,b] \times [a,b] \longrightarrow \mathbb{R} $ and $ \phi : [a,b] \times [a,b] \longrightarrow \mathbb{R} $ 
	be continuous functions and suppose there exists an $ M $ such that
	\begin{align*}
		|K(x,y)| \leq M & & \forall (a,y) \in [a,b] \times [a,b] 
	\end{align*}
	then the Volterra equation 
	\begin{align}
		\label{eq:volt-1}
		f(x) = \lambda \int_a^x K(x,y) f(y)dy + \phi(x) 
	\end{align}
	has a unique solution on for $ f $ on $ [a, b] $.
\end{lemma}
\begin{proof}
	Define the operator $ A : C[a,b] \longrightarrow C[a,b] $ 
	by
	\begin{align*}
		(Af)(x) = \lambda \int_a^x K(x,y)f(y)dy + \phi(x). 
	\end{align*}
	Let $ f, g \in C[a,b] $ and see that
	\begin{align*}
		|(Af)(x) - (Ag)(x)| &= \vert \lambda \int_a^x K(x,y)[f(y) - g(y)]dy \vert \\
			&\leq | \lambda | \int_a^x|K(x,y)[ f(y)-g(y)]|dy \\
			&\leq | \lambda | M(x-y) \max_{x\in [a,b]} \left\{ |f(y) - g(y) |\right\} \\
	\end{align*}
	In a similar maner it follows that
	\begin{align*}
		|(A^nf)(x) - (A^ng)(x)| \leq \underbrace{|\lambda^n|M^n \frac{(b-a)^n}{n!}\max_{x\in[a,b]}\left\{ | f(x) - g(x) | \right\}}_{\circledast}
	\end{align*}
	so 
	\begin{align*}
		\rho(A^nf, A^ng) \leq |\lambda^n|M^n \frac{(b-a)^n}{n!}\rho(f,g)
	\end{align*}
	where $ \rho $ is the usual metric on $ C[a,b] $.
	It can be seen that for any $ \lambda $ it is possible to choose an $ n $ which will make $\circledast $ arbitrarily small.
	So by corollary \ref{cor:banach-fixed-point} we have that there must exist a unique fixed point $ h $ such that
	$ (Ah)(x) = h(x) $, which means that there exists a unique solution to \eqref{eq:volt-1} on $ [a, b] $.
\end{proof}

To fully prove the existence and uniqueness of solutions to 

\begin{lemma}
\label{lem:fde_volt_equiv}
If the function $ f $ is continuous, then the initial value problem
\begin{align}
	\label{eq:fde-2}
	\capder{0}{\alpha}{y}(t) &= f(t,y(t))
\end{align}
along with 
\begin{align}
	\label{eq:fde-2-ic}
	y^{(k)}(0) &= \gamma_k & k=0,1,\ldots, n-1 
\end{align}
where $ n = \lceil \alpha \rceil $
is equivalent to the non-linear Volterra equation of the second kind,
\begin{align*}
	y(t) = \sum_{k=0}^{n-1} \frac{t^k}{k!} \gamma_k + \frac{1}{\Gamma(\alpha)} \int_0^t (t-u)^{\alpha-1} f(u,y(u))du.
\end{align*}
\end{lemma}
\begin{proof}
	Apply $ I_0^\alpha $ to both sides of \eqref{eq:fde-2} to get
	\begin{align}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) &= \rli{0}{\alpha}{f(t,y(t))} \nonumber \\
		\label{eq:fde-volt-equiv-1}
 		\frac{1}{\Gamma(\alpha)\Gamma(n-\alpha)} \int_0^t \int_0^x (t-x)^{\alpha-1}(x-u)^{n-\alpha-1}y^{(n)}(u) du dx &= \frac{1}{\Gamma(\alpha)} \int_0^t (t-u)^{\alpha-1} f(u,f(u))du 
	\end{align}
	then considering just the left hand side we have that 
	\begin{align*}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) &= \frac{1}{\Gamma(\alpha)\Gamma(n-\alpha)} \int_0^t \int_0^x (t-x)^{\alpha-1}(x-u)^{n-\alpha-1}y^{(n)}(u) du dx. \\
	\end{align*}
	This integral is over the region 
	\begin{align*}
		R :=
		\begin{cases}
			0 \leq u \leq x \\
			0 \leq x \leq t
		\end{cases}
	\end{align*}
	which is equivalent to 
		\begin{align*}
		R' :=
		\begin{cases}
			0 \leq u \leq t \\
			u \leq x \leq t
		\end{cases}
	\end{align*}
	so we can change the order of integration to get
	\begin{align*}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) &= \frac{1}{\Gamma(\alpha)\Gamma(n-\alpha)} \int_0^t y^{(n)}(u) \underbrace{\left(\int_u^t (t-x)^{\alpha-1}(x-u)^{n-\alpha-1} dx \right)}_{\circledast} du.\\
	\end{align*}
	Focusing just on $ \circledast $ and by performing the change of variables $ \tau = \frac{x-u}{t-u} $ we get that
	\begin{align*}
		\circledast &= (t-u)^{n-1} \int_0^1 (1-\tau)^{\alpha-1}\tau^\alpha d\tau \\
			&= (t-u)^{n-1} B(\alpha, n-\alpha) \\
			&= (t-u)^{n-1} \frac{\Gamma(\alpha)\Gamma(n-\alpha)}{\Gamma(n)}.
	\end{align*}
	So we have that 
	\begin{align*}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) = \underbrace{\frac{1}{\Gamma(n)} \int_0^t (t-u)^{n-1} y^{(n)}(u) du}_{\circledast \circledast}.
	\end{align*}
	Now by considering the Cauchy formula for repeated integration we can see that $ \circledast \circledast $ is just the $n-$fold integral
	of $ f $ based at $ 0 $ and so
	\begin{align*}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) &= \int_0^t \int_0^{t_1} \int_0^{t_2} \cdots \int_0^{n-1} y^{(n)}(u) du dt_{n-1} dt_{n-2} \cdots dt_{1} \\
			&= \int_0^t \int_0^{t_1} \int_0^{t_2} \cdots \int_0^{n-2} \left(y^{(n-1)}(t_{n-1}) - y^{(n)}(0) \right)dt_{n-1}dt_{n-2}\cdots dt_{1} \\
			&= \int_0^t \int_0^{t_1} \int_0^{t_2} \cdots \int_0^{n-3} \left(y^{(n-2)}(t_{n-2}) - y^{(n)}(0) - ty^{(n)}(0) \right)dt_{n-1}dt_{n-2}\cdots dt_{1} \\
			&= y(t) - \sum_{k=0}^{n-1} \frac{t^k f^{(k)}(0)}{k!}.
	\end{align*}
	Applying the initial conditions in \eqref{eq:fde-2-ic} we get that 
	\begin{align*}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) = y(t) - \sum_{k=0}^{n-1} \frac{t^k}{k!} \gamma_k
	\end{align*}
	and by substituting back into \eqref{eq:fde-volt-equiv-1} and rearranging we have
	\begin{align*}
		y(t) = \sum_{k=0}^{n-1} \frac{t^k}{k!} \gamma_k + \frac{1}{\Gamma(\alpha)} \int_0^t (t-u)^{\alpha-1} f(u,y(u))du.
	\end{align*}
\end{proof}


\bibliographystyle{plain}
\bibliography{references}
\end{document}
