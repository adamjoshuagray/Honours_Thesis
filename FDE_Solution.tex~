\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf}
\usepackage[a4paper]{geometry}
\usepackage{fancyhdr}
\usepackage{mathtools}
\pagestyle{fancy}
\begin{document}

\setlength\parindent{0pt}
\setlength{\parskip}{5mm plus4mm minus3mm}
\fancyfoot[l]{Adam J. Gray}
\fancyfoot[r]{\today}
\fancyhead[l]{BlackHat Maths}
\fancyhead[r]{Solution to a Simple FDE}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newcommand{\laplace}[1]{ \mathcal{L} \left\{ #1 \right\} }
\newcommand{\rld}[3]{ \left( \mathcal{D}_{#1}^{#2} #3 \right) }
\newcommand{\rli}[3]{ \left( I_{#1}^{#2} #3 \right) }
\newcommand{\der}[3]{ \frac{d^{#3}#1}{d#2^{#3}} }
\newcommand{\capder}[3]{ \left( \prescript{C}{}{\mathcal{D}_{#1}^{#2}} #3 \right) }
\section*{Solution to a Simple FDE}

We aim to get a solution to the following fractional differential equation (in terms of Caputo derivatives)


\begin{align}
	\label{eq:fde-1}
	\left( \prescript{C}{}{\mathcal{D}_0^\alpha}y \right)(t) = \beta y(t) 
\end{align}

along with the initial conditions 
\begin{align}
	\label{eq:fde-1-ic}
	y^{(k)}(0) = 
	\begin{cases}
		1 & k = 0 \\
		0 & 1 \leq k \leq \lfloor \alpha \rfloor - 1  
	\end{cases}
\end{align}

has the solution $ y(t) = E_\alpha \left( \beta t^\alpha \right) $. Where $ E_\alpha $ is the one parameter Mittag-Lefler function.

This solution is arrived at by a Laplace transform method. We will then go on to show that this solution is unique. The proof of that fact, will be 
presented via the proof of a more general theorem, which broadly follows a Banach fixed point method. 

\begin{definition}[Fractional Derivatives and Integrals]
	For $ \alpha > 0 $ we define
	\begin{align*}
		(I_{a+}^{\alpha}f)(x) := \frac{1}{\Gamma(\alpha)}\int_a^x \frac{f(t)}{(x-t)^{1 - \alpha}} dt \\
		(\mathcal{D}_{a+}^{\alpha}f)(x) := \frac{1}{\Gamma(n-\alpha)} \frac{d^n}{dx^n}\int_a^x \frac{f(t)}{(x-t)^{\alpha - n + 1}} dt \\
		(\prescript{C}{}{\mathcal{D}}_{a+}^\alpha f)(x) := I_{0}^{n-\alpha} \frac{d^n}{dx^n}f(x) 
	\end{align*}
	where $ n  = \lceil \alpha \rceil - 1$.
	We will refer to $ I_{a+}^\alpha f$ as the (Riemann Louiville) integral $ f $ of over $ \alpha $ (based at $ a $).
	Likewise we refer to $ \mathcal{D}_{a+}^\alpha f $ as the (Riemann Louiville) derivative of order $ \alpha $ (based at $ a $).
	We also refer to $ \prescript{C}{}{\mathcal{D}}_{a+}^\alpha f $ as the Caputo derivative of order $ \alpha $ (based at $ a $).
	
\end{definition}

The motivation for these definitions are based of the Cauchy formula for repeated integration, and in the case
of the Caputo derivative, practical considerations. \cite{Samko1993, Podlubny1999} 

For the rest of our considerations we will take $ a = 1 $ (based at 0). 

We now consider the Laplace transform of the fractional integration and differentiation operators.

\begin{lemma}
	$$
		\mathcal{L} \left\{ I_0^\alpha f \right\}  = s^{-\alpha} \mathcal{L} \left\{ f \right\}
	$$
\end{lemma}
\begin{proof}
	Since 
	$$
		 (I_0^\alpha f)(t) = \frac{1}{\Gamma(\alpha)} \int_0^x f(u) (t-u)^{\alpha - 1} du
	$$
	is just $ \frac{1}{\Gamma(\alpha)} $ times the convolution of $ f $ with $ t^{\alpha - 1} $ then by the convolution theorem
	for Laplace transforms we have that 
	\begin{align*}
		\mathcal{L} \left\{ I_0^\alpha f \right\} &= \frac{1}{\Gamma(\alpha)} \mathcal{L} \left\{ \int_{0}^{t} f(u) (t-u)^{\alpha - 1} du \right\} \\
			&= \frac{1}{\Gamma(\alpha)} \mathcal{L} \left\{ f(t) \right\} \underbrace{\mathcal{L} \left\{ t^{\alpha - 1} \right\}}_{=s^{-\alpha} \Gamma(\alpha)} \\
			&= s^{-\alpha} \mathcal{L} \left\{ f \right\}.
	\end{align*}
\end{proof}

\begin{lemma}
	\begin{align*}
		\mathcal{L} \left\{\mathcal{D}_0^\alpha f\right\} = s^\alpha \mathcal{L} \left\{ f \right\} - \sum_{k=0}^{n-1} s^{k-1} \left( \mathcal{D}_0^{\alpha-k} f\right)(0)
	\end{align*}
\end{lemma}
\begin{proof}
	See that
	\begin{align*}
		\laplace{ \rld{0}{\alpha}{f} } &= \laplace{ \der{}{t}{n} \rli{0}{n-\alpha}{f} } \\
			&= s\laplace{\rli{0}{n-\alpha}{f}} - \sum_{k=0}^{n-1} s^k \der{}{t}{n-k-1} \rli{0}{n-\alpha}{f}(0) \\
			&= s\laplace{\rli{0}{n-\alpha}{f}} - \sum_{k=0}^{n-1} s^{k-1} \rld{0}{\alpha - k}{f}(0). 
	\end{align*}
\end{proof}

\begin{lemma}
\label{lem:lap_cap}

	\begin{align*}
		\laplace{\capder{0}{\alpha}{f}} = s^{\alpha - n} \left[ s^n \laplace{f} - \sum_{k=0}^{n-1} s^{n-k-1} \left( \der{f}{t}{k} \right)(0) \right]
	\end{align*}
\end{lemma}
\begin{proof}
	See that
	\begin{align*}
		\laplace{\capder{0}{\alpha}{f}} &= \laplace{ \frac{1}{\Gamma(n-\alpha)} \rli{0}{n-\alpha}{\der{f}{t}{n}}} \\
			&= \frac{1}{\Gamma(n-\alpha)}\laplace{ \int_0^t (t-u)^{n-\alpha-1} \der{f}{t}{n} du} \\ 
	\end{align*}
	which is the Laplace transform of a convolution so
	\begin{align*}
		\Gamma(n-\alpha)\laplace{ \int_0^t (t-u)^{n-\alpha-1} \der{f}{t}{n} du} &= \laplace{t^{n-\alpha-1}} \laplace{\der{f}{t}{n}} \\
		&= \frac{1}{n-\alpha} \left( s^{-(n-\alpha)} \Gamma(n-\alpha) \right) \left( s^n \laplace{f} - \sum_{k=0}^{n-1} s^{n-k-1} \left( \der{f}{t}{k} \right)(0) \right) \\
		&= s^{\alpha - n} \left[ s^n \laplace{f} - \sum_{k=0}^{n-1} s^{n-k-1} \left( \der{f}{t}{k} \right)(0) \right].
	\end{align*}	
\end{proof}

We now define the Mittag-Lefler function and calculate its Laplace transform.

\begin{definition}
	The one parameter Mittag-Lefler $ E_\alpha $ function is defined by its power series.
	$$
		E_\alpha(t) = \sum_{k=0}^{\infty} \frac{t^k}{\Gamma(\alpha k + 1)}
	$$
\end{definition}
It is clear to see the definition of this function is inspired by the exponential function. Before we can calculate the 
Laplace transform of the Mittag-Lefler function we have to prove a simple lemma about the convergence of the 
series which is used in its definition.

\begin{lemma}
\label{lem:mit_conv}

	The series
	$$
		\sum_{k=0}^{\infty} \frac{t^k}{\Gamma(\alpha k + 1)} 
	$$
  	converges absolutely for all $ t \in \mathbb{R} $.
\end{lemma}
\begin{proof}
	Let $ a_k = \frac{t^k}{\Gamma(\alpha k + 1) }$ and see that
	$$ \lvert \frac{a_{k+1}}{a_k} \rvert = |t| \frac{\Gamma(\alpha k + 1) }{\Gamma(\alpha(k+1) + 1)} $$
	and that hence 
	$$
		\lim_{k \longrightarrow \infty} \lvert \frac{a_{k+1}}{a_k} \rvert = 0
	$$
	for all $ t \in \mathbb{R} $ so by the ratio test, the series $ \sum_{k=0}^{\infty} \frac{t^k}{\Gamma(\alpha k + 1)}  $
	converges for all $ t \in \mathbb{R} $.
\end{proof}
\begin{lemma}
\label{lem:lap_mit}

	\begin{align*}	
		\laplace{ E_\alpha (\beta t^\alpha)} = \frac{s^{\alpha - 1}}{s^\alpha - \beta}
	\end{align*}
\end{lemma}
\begin{proof}
	See that
	\begin{align*}
		\laplace{ E_\alpha (\beta t^\alpha)} = \int_0^\infty e^{-st} \sum_{k=0}^\infty \frac{(\beta t^\alpha)^k}{\Gamma(\alpha k+1)} dt
	\end{align*}
	and because the series converges absolutely for all $ t \in \mathbb{R} $ (lemma \ref{lem:mit_conv}) we may interchange the integral
	and the sum to get
	\begin{align*}
		\int_0^\infty e^{-st} \sum_{k=0}^\infty \frac{(\beta t^\alpha)^k}{\Gamma(\alpha k+1)} dt &= \sum_{k=0}^\infty \int_0^\infty e^{-st} \frac{(\beta t^\alpha)^k}{\Gamma(\alpha k + 1)} dt \\
			&= \sum_0^\infty \frac{\beta^k}{\Gamma(\alpha k + 1)} \int_0^\infty e^{-st} t^{\alpha k} dt. \\
	\end{align*}
	By performing the change of variables $ x =st $ we get that 
	\begin{align*}
		\sum_0^\infty \frac{\beta^k}{\Gamma(\alpha k + 1)} \int_0^\infty e^{-st} t^{\alpha k} dt 
			&= \sum_0^\infty \frac{\beta^k s^{-(k+1)}}{\Gamma(\alpha k + 1)} \underbrace{\int_0^\infty e^{-x} x^{\alpha k} dx}_{\Gamma(\alpha k + 1)} \\
			&= \sum_{k=0}^\infty \beta^{k} s^{-(\alpha k + 1)} \\
			&= \frac{s^{\alpha-1}}{s^\alpha - \beta}.		
	\end{align*}
	So we have that 
	\begin{align*}	
		\laplace{ E_\alpha (\beta t^\alpha)} = \frac{s^{\alpha - 1}}{s^\alpha - \beta}
	\end{align*}	
	as required.
\end{proof}

We now have sufficient tools to attack the original problem, that is finding a solution to \eqref{eq:fde-1}, \eqref{eq:fde-1-ic}.

\begin{lemma}
	The FDE defined in \eqref{eq:fde-1} and \eqref{eq:fde-1-ic}, restated here for completness 
	\begin{align*}
		\left( \prescript{C}{}{\mathcal{D}_0^\alpha}y \right)(t) = \beta y(t) 
	\end{align*}

	along with the initial conditions 
	\begin{align*}
		y^{(k)}(0) = 
		\begin{cases}
			1 & k = 0 \\
			0 & 1 \leq k \leq \lfloor \alpha \rfloor - 1  
		\end{cases}
	\end{align*}
	has solution $ y(t) = E_\alpha \left( \beta t^\alpha \right) $.
\end{lemma}
\begin{proof}
	Taking the Laplace transform of both sides of \eqref{eq:fde-1} yields
	\begin{align*}
		\laplace{\capder{0}{\alpha}{y}} &= \beta \laplace{y} \\
		s^{-(n+\alpha)} \left[s^n \laplace{y} - \sum_{k=0}^{n-1} s^{n-k-1} y^{(k)}(0) \right] &= \beta \laplace{y}
	\end{align*}
	by the result of lemma \ref{lem:lap_cap}. 
	Then taking into account \eqref{eq:fde-1-ic} we get
	\begin{align*}
		s^{-(n+\alpha)} \left[s^n \laplace{y} - s^{n-1}\right] &= \beta \laplace{y}
	\end{align*}
	and so 
	\begin{align*}
		\laplace{y} = \frac{s^{\alpha-1}}{s^\alpha - \beta}.
	\end{align*}
	By using the result of lemma \ref{lem:lap_mit} we have that 
	\begin{align*}
		y(t) = E_\alpha(\beta t^\alpha)
	\end{align*}
\end{proof}

An obvious question to ask now, is whether the solution to \eqref{eq:fde-1}, \eqref{eq:fde-1-ic} is unique. To answer this in 
affermative we will prove a result about the existance and uniqueness of solutions to non-linear Voltera integral equations of the second kind
then show that a more general FDE is equivelent to such a Voltera integral equation and hence arrive at the desired result. 
This technique follows that in \cite{Diethelm2002}. This 
is more general than what is required here, but it lays the groundwork for future results.

\begin{lemma}
\label{lem:fde_volt_equiv}
If the function $ f $ is continuous, then the initial value problem
\begin{align}
	\label{eq:fde-2}
	\capder{0}{\alpha}{y}(t) &= f(t,y(t))
\end{align}
along with 
\begin{align}
	y^{(k)}(0) &= \gamma_k & k=0,1,\ldots, n-1 
\end{align}
where $ n = \lceil \alpha \rceil $
is equivelent to the non-linear Voltera equation of the second kind,
\begin{align*}
	y(t) = \sum_{k=0}^{n-1} \frac{t^k}{k!} \gamma_k + \frac{1}{\Gamma(\alpha)} \int_0^t (t-u)^{\alpha-1} f(u,y(u))du.
\end{align*}
\end{lemma}
\begin{proof}
	Apply $ I_0^\alpha $ to both sides of \eqref{eq:fde-2} to get
	\begin{align}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) &= \rli{0}{\alpha}{f(t,y(t))} \nonumber \\
		\label{eq:fde-volt-equiv-1}
 		\frac{1}{\Gamma(\alpha)\Gamma(n-\alpha)} \int_0^t \int_0^x (t-x)^{\alpha-1}(x-u)^{n-\alpha-1}y^{(n)}(u) du dx &= \frac{1}{\Gamma(\alpha)} \int_0^t (t-u)^{\alpha-1} f(u,f(u))du 
	\end{align}
	then considering just the left hand side we have that 
	\begin{align*}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) &= \frac{1}{\Gamma(\alpha)\Gamma(n-\alpha)} \int_0^t \int_0^x (t-x)^{\alpha-1}(x-u)^{n-\alpha-1}y^{(n)}(u) du dx. \\
	\end{align*}
	This integral is over the region 
	\begin{align*}
		R :=
		\begin{cases}
			0 \leq u \leq x \\
			0 \leq x \leq t
		\end{cases}
	\end{align*}
	which is equivelent to 
		\begin{align*}
		R' :=
		\begin{cases}
			0 \leq u \leq t \\
			u \leq x \leq t
		\end{cases}
	\end{align*}
	so we can change the order of integration to get
	\begin{align*}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) &= \frac{1}{\Gamma(\alpha)\Gamma(n-\alpha)} \int_0^t y^{(n)}(u) \underbrace{\left(\int_u^t (t-x)^{\alpha-1}(x-u)^{n-\alpha-1} dx \right)}_{\circledast} du.\\
	\end{align*}
	Focusing just on $ \circledast $ and by performing the change of variables $ \tau = \frac{x-u}{t-u} $ we get that
	\begin{align*}
		\circledast &= (t-u)^{n-1} \int_0^1 (1-\tau)^{\alpha-1}\tau^\alpha d\tau \\
			&= (t-u)^{n-1} B(\alpha, n-\alpha) \\
			&= (t-u)^{n-1} \frac{\Gamma(\alpha)\Gamma(n-\alpha)}{\Gamma(n)}.
	\end{align*}
	So we have that 
	\begin{align*}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) = \underbrace{\frac{1}{\Gamma(n)} \int_0^t (t-u)^{n-1} y^{(n)}(u) du}_{\circledast \circledast}.
	\end{align*}
	Now by considering the Cauchy formula for repeated integration we can see that $ \circledast \circledast $ is just the $n-$fold integral
	of $ f $ based at $ 0 $ and so
	\begin{align*}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) &= \int_0^t \int_0^{t_1} \int_0^{t_2} \cdots \int_0^{n-1} y^{(n)}(u) du dt_{n-1} dt_{n-2} \cdots dt_{1} \\
			&= \int_0^t \int_0^{t_1} \int_0^{t_2} \cdots \int_0^{n-2} \left(y^{(n-1)}(t_{n-1}) - y^{(n)}(0) \right)dt_{n-1}dt_{n-2}\cdots dt_{1} \\
			&= \int_0^t \int_0^{t_1} \int_0^{t_2} \cdots \int_0^{n-3} \left(y^{(n-2)}(t_{n-2}) - y^{(n)}(0) - ty^{(n)}(0) \right)dt_{n-1}dt_{n-2}\cdots dt_{1} \\
			&= y(t) - \sum_{k=0}^{n-1} \frac{t^k f^{(k)}(0)}{k!}.
	\end{align*}
	Applying the initial conditions in \ref{eq:fde-2-iv} we get that 
	\begin{align*}
		\rli{0}{\alpha}{\rld{0}{\alpha}{y}}(t) = y(t) - \sum_{k=0}^{n-1} \frac{t^k}{k!} \gamma_k
	\end{align*}
	and by subsituting back into \eqref{eq:fde-volt-equiv-1} and rearranging we have
	\begin{align*}
		y(t) = \sum_{k=0}^{n-1} \frac{t^k}{k!} \gamma_k + \frac{1}{\Gamma(\alpha)} \int_0^t (t-u)^{\alpha-1} f(u,y(u))du.
	\end{align*}
\end{proof}


\bibliographystyle{plain}
\bibliography{references}
\end{document}
